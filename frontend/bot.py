#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Crypto Trading Bot - Discord Bot ç‰ˆæœ¬ï¼ˆå®Œæ•´ç‰ˆï¼‰
æ”¯æŒå¤šäº¤æ˜“å°ã€å¤šæ™‚é–“æ¡†æ¶ã€ä½¿ç”¨è¨“ç·´çš„ ML æ¨¡å‹ç”ŸæˆçœŸå¯¦ä¿¡è™Ÿ
"""

import os
import asyncio
import logging
from datetime import datetime
from dotenv import load_dotenv
import discord
from discord.ext import commands, tasks
from flask import Flask
import threading
import pickle
import json
import numpy as np
import pandas as pd
from pathlib import Path
from sklearn.preprocessing import StandardScaler

# å¯¼å…¥ä½ çš„ strategy.py
import sys
sys.path.insert(0, os.path.dirname(__file__))
try:
    from strategy import TradingStrategy, TargetGenerator
except ImportError:
    logging.warning("âš ï¸ Cannot import strategy.py, using dummy strategy")

# ===== é…ç½®æ—¥èªŒ =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ===== è¼‰å…¥ç’°å¢ƒè®Šæ•¸ =====
load_dotenv()

DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")
DISCORD_CHANNEL_ID = os.getenv("DISCORD_CHANNEL_ID")
HF_REPO_ID = os.getenv("HF_REPO_ID")
HF_TOKEN = os.getenv("HF_TOKEN")

# é©—è­‰ç’°å¢ƒè®Šæ•¸
if not all([DISCORD_TOKEN, DISCORD_CHANNEL_ID, HF_REPO_ID, HF_TOKEN]):
    logger.error("âŒ éŒ¯èª¤ï¼šç¼ºå°‘å¿…è¦çš„ç’°å¢ƒè®Šæ•¸")
    logger.error(" éœ€è¦: DISCORD_TOKEN, DISCORD_CHANNEL_ID, HF_REPO_ID, HF_TOKEN")
    exit(1)

try:
    DISCORD_CHANNEL_ID = int(DISCORD_CHANNEL_ID)
except ValueError:
    logger.error("âŒ éŒ¯èª¤ï¼šDISCORD_CHANNEL_ID å¿…é ˆæ˜¯æ•¸å­—")
    exit(1)

# ===== Discord Bot é…ç½® =====
intents = discord.Intents.default()
intents.message_content = True
intents.members = True
intents.guilds = True

# ç¦ç”¨å…§å»º help æŒ‡ä»¤ï¼Œé¿å…è¡çª
bot = commands.Bot(command_prefix="!", intents=intents, help_command=None)

# ===== é…ç½® - å¾ .env è®€å– =====
def get_env_list(key, default):
    val = os.getenv(key)
    if not val:
        return default
    return [x.strip() for x in val.split(',')]

CONFIG = {
    "trading_pairs": get_env_list("TRADING_PAIRS", [
        "BTC/USDT", "ETH/USDT", "BNB/USDT", "SOL/USDT", "XRP/USDT",
        "AAPL", "GOOGL", "MSFT", "AMZN", "TSLA", "NVDA", "META", "BTC-USD"
    ]),
    # é€™è£¡åŒ…å«æ‰€æœ‰å¯èƒ½çš„æ™‚é–“æ¡†æ¶ (ç¾è‚¡ 1d, åŠ å¯† 4h)
    "timeframes": ["15m", "1h", "4h", "1d"],
    "model_dir": "./models",
    "hf_repo_id": HF_REPO_ID,
    "hf_token": HF_TOKEN,
    "discord_channel_id": DISCORD_CHANNEL_ID,
}

# ===== äº¤æ˜“ä¿¡è™Ÿåƒæ•¸é…ç½®ï¼ˆå¯èª¿æ•´ï¼‰=====
SIGNAL_CONFIG = {
    "model_confidence_threshold": 0.55,  # æ¨¡å‹é æ¸¬æ¦‚ç‡é–¾å€¼
    "min_samples": 100,  # æœ€å°‘éœ€è¦å¤šå°‘æ ¹ K ç·šä¾†è¨ˆç®—ç‰¹å¾µ
    "signal_type": "buy",  # "buy", "sell", æˆ– "both"
}

# ===== æ¨¡å‹ç®¡ç† =====
class ModelManager:
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.model_dir = CONFIG["model_dir"]
        Path(self.model_dir).mkdir(exist_ok=True)

    def get_model_filename(self, pair, timeframe):
        """ç”Ÿæˆæ¨¡å‹æ–‡ä»¶å"""
        pair_clean = pair.replace('/', '_').replace('^', '').replace('=', '_').replace('-', '_')
        return f"model_{pair_clean}_{timeframe}.pkl"
    
    def get_scaler_filename(self, pair, timeframe):
        """ç”Ÿæˆ scaler æ–‡ä»¶å"""
        pair_clean = pair.replace('/', '_').replace('^', '').replace('=', '_').replace('-', '_')
        return f"scaler_{pair_clean}_{timeframe}.pkl"

    def download_all_models(self):
        """ä¸‹è¼‰æ‰€æœ‰æ¨¡å‹"""
        logger.info("ğŸ“¥ é–‹å§‹ä¸‹è¼‰æ‰€æœ‰æ¨¡å‹...")
        try:
            from huggingface_hub import hf_hub_download
        except ImportError:
            logger.error("âŒ ç¼ºå°‘ huggingface-hub åŒ…")
            return False

        total = len(CONFIG["trading_pairs"]) * len(CONFIG["timeframes"])
        downloaded = 0

        for pair in CONFIG["trading_pairs"]:
            for timeframe in CONFIG["timeframes"]:
                
                # é€™è£¡ä¹Ÿè¦åŠ ä¸Šåˆ¤æ–·ï¼Œé¿å…å˜—è©¦ä¸‹è¼‰ä¸å­˜åœ¨çš„çµ„åˆ
                is_crypto = '/' in pair
                if is_crypto and timeframe == '1d':
                    continue
                if not is_crypto and timeframe == '4h':
                    continue

                model_filename = self.get_model_filename(pair, timeframe)
                scaler_filename = self.get_scaler_filename(pair, timeframe)
                
                model_path = os.path.join(self.model_dir, model_filename)
                scaler_path = os.path.join(self.model_dir, scaler_filename)

                try:
                    # ä¸‹è¼‰æ¨¡å‹
                    if not os.path.exists(model_path):
                        hf_hub_download(
                            repo_id=CONFIG["hf_repo_id"],
                            filename=model_filename,
                            local_dir=self.model_dir,
                            token=CONFIG["hf_token"]
                        )
                    
                    # ä¸‹è¼‰ scaler
                    if not os.path.exists(scaler_path):
                        hf_hub_download(
                            repo_id=CONFIG["hf_repo_id"],
                            filename=scaler_filename,
                            local_dir=self.model_dir,
                            token=CONFIG["hf_token"]
                        )
                    
                    downloaded += 1

                except Exception as e:
                    pass

        logger.info(f"ğŸ“Š ä¸‹è¼‰å®Œæˆï¼Œæœ¬åœ°å…±æœ‰ {downloaded} çµ„æ¨¡å‹")
        return downloaded > 0

    def load_model(self, pair, timeframe):
        """è¼‰å…¥æ¨¡å‹å’Œ scaler"""
        model_filename = self.get_model_filename(pair, timeframe)
        scaler_filename = self.get_scaler_filename(pair, timeframe)
        
        model_path = os.path.join(self.model_dir, model_filename)
        scaler_path = os.path.join(self.model_dir, scaler_filename)

        if not os.path.exists(model_path):
            return None, None

        try:
            with open(model_path, 'rb') as f:
                model = pickle.load(f)
            
            scaler = None
            if os.path.exists(scaler_path):
                with open(scaler_path, 'rb') as f:
                    scaler = pickle.load(f)
            
            return model, scaler

        except Exception as e:
            logger.error(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•— {pair} {timeframe}: {str(e)}")
            return None, None

# ===== äº¤æ˜“ä¿¡è™Ÿé‚è¼¯ =====
class SignalGenerator:
    def __init__(self):
        self.strategy = TradingStrategy()
    
    def generate_signal(self, pair, timeframe, model, scaler, historical_data_df):
        """ç”Ÿæˆäº¤æ˜“ä¿¡è™Ÿ"""
        
        if model is None:
            return {
                "pair": pair,
                "timeframe": timeframe,
                "action": "HOLD",
                "confidence": 0.0,
                "reason": "No model available",
                "timestamp": datetime.now().isoformat()
            }
        
        try:
            # è¨ˆç®—ç‰¹å¾µ
            if len(historical_data_df) < SIGNAL_CONFIG["min_samples"]:
                return {
                    "pair": pair,
                    "timeframe": timeframe,
                    "action": "HOLD",
                    "confidence": 0.0,
                    "reason": f"Insufficient data ({len(historical_data_df)})",
                    "timestamp": datetime.now().isoformat()
                }
            
            features_df = self.strategy.calculate_features(historical_data_df)
            
            if len(features_df) == 0:
                return {
                    "pair": pair,
                    "timeframe": timeframe,
                    "action": "HOLD",
                    "confidence": 0.0,
                    "reason": "Feature calc failed",
                    "timestamp": datetime.now().isoformat()
                }
            
            # å–æœ€å¾Œä¸€è¡Œæ•¸æ“š
            feature_columns = self.strategy.get_feature_columns()
            # ç¢ºä¿ç‰¹å¾µæ¬„ä½å°é½Š
            current_features = [c for c in features_df.columns if c in feature_columns]
            if not current_features:
                 return {"pair": pair, "action": "HOLD", "confidence": 0.0, "reason": "Features mismatch"}

            latest_features = features_df[feature_columns].iloc[-1].values.reshape(1, -1)
            
            # æ¨™æº–åŒ–ç‰¹å¾µ
            if scaler is not None:
                latest_features = scaler.transform(latest_features)
            
            # æ¨¡å‹é æ¸¬
            prediction = model.predict(latest_features)[0]  # 0, 1, -1
            
            # ç²å–é æ¸¬æ¦‚ç‡
            if hasattr(model, 'predict_proba'):
                probas = model.predict_proba(latest_features)[0]
                confidence = np.max(probas)
            else:
                confidence = 0.5
            
            # æ±ºå®šæ˜¯å¦ç™¼é€ä¿¡è™Ÿ
            action = "HOLD"
            if prediction == 1 and confidence >= SIGNAL_CONFIG["model_confidence_threshold"]:
                if SIGNAL_CONFIG["signal_type"] in ["buy", "both"]:
                    action = "BUY"
            elif prediction == -1 and confidence >= SIGNAL_CONFIG["model_confidence_threshold"]:
                if SIGNAL_CONFIG["signal_type"] in ["sell", "both"]:
                    action = "SELL"
            
            current_price = historical_data_df['close'].iloc[-1]
            
            return {
                "pair": pair,
                "timeframe": timeframe,
                "action": action,
                "prediction": prediction,
                "confidence": float(confidence),
                "current_price": float(current_price),
                "reason": "Model prediction",
                "timestamp": datetime.now().isoformat()
            }
        
        except Exception as e:
            logger.error(f"âŒ Signal generation error for {pair} {timeframe}: {str(e)}")
            return {
                "pair": pair,
                "timeframe": timeframe,
                "action": "HOLD",
                "confidence": 0.0,
                "reason": "Error",
                "timestamp": datetime.now().isoformat()
            }

# ===== æ•¸æ“šç²å–ï¼ˆBinance + yfinanceï¼‰ =====
class DataFetcher:
    """ç²å–æ­·å²æ•¸æ“š"""
    
    @staticmethod
    def get_sample_data(pair, timeframe, n_bars=300):
        """æ ¹æ“šäº¤æ˜“å°è‡ªå‹•é¸æ“‡æ•¸æ“šæº"""
        is_crypto_pair = '/' in pair  # ä¾‹å¦‚ BTC/USDT
        
        if is_crypto_pair:
            return DataFetcher._fetch_binance_data(pair, timeframe, n_bars)
        else:
            return DataFetcher._fetch_yfinance_data(pair, timeframe, n_bars)

    @staticmethod
    def _fetch_binance_data(pair, timeframe, n_bars):
        try:
            import ccxt
            exchange = ccxt.binance()
            
            # è½‰æ›æ™‚é–“æ¡†æ¶å­—ä¸²
            tf_map = {"15m": "15m", "1h": "1h", "4h": "4h", "1d": "1d"}
            ccxt_tf = tf_map.get(timeframe, "1h")
            
            ohlcv = exchange.fetch_ohlcv(pair, ccxt_tf, limit=n_bars)
            
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            
            return df[['open', 'high', 'low', 'close', 'volume']]
            
        except Exception as e:
            logger.warning(f"âš ï¸ Binance fetch failed for {pair}: {e}")
            return DataFetcher._generate_dummy_data(n_bars)

    @staticmethod
    def _fetch_yfinance_data(pair, timeframe, n_bars):
        try:
            import yfinance as yf
            
            # èª¿æ•´ yfinance åƒæ•¸
            if timeframe == "15m":
                period = "5d"
                interval = "15m"
            elif timeframe == "1h":
                period = "60d"
                interval = "1h"
            else:  # 1d
                period = "730d"
                interval = "1d"
            
            df = yf.download(
                pair, 
                period=period, 
                interval=interval, 
                progress=False, 
                auto_adjust=False,
                multi_level_index=False
            )
            
            if len(df) < SIGNAL_CONFIG["min_samples"]:
                return DataFetcher._generate_dummy_data(n_bars)
            
            # è™•ç† MultiIndex
            if isinstance(df.columns, pd.MultiIndex):
                df.columns = df.columns.get_level_values(0)
            
            # çµ±ä¸€æ¬„ä½åç¨±
            df.columns = [str(c).capitalize() for c in df.columns]
            
            required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
            if not all(col in df.columns for col in required_cols):
                return DataFetcher._generate_dummy_data(n_bars)
                
            df = df[required_cols].tail(n_bars)
            df.columns = ['open', 'high', 'low', 'close', 'volume']
            df = df.reset_index(drop=True)
            
            return df
            
        except Exception as e:
            logger.warning(f"âš ï¸ yfinance fetch failed for {pair}: {e}")
            return DataFetcher._generate_dummy_data(n_bars)
    
    @staticmethod
    def _generate_dummy_data(n_bars=200):
        """ç”Ÿæˆæ¨¡æ“¬æ•¸æ“šï¼ˆæœ€å¾Œæ‰‹æ®µï¼‰"""
        np.random.seed(42)
        prices = np.cumsum(np.random.randn(n_bars)) + 100
        data = {
            'open': prices,
            'high': prices + 1,
            'low': prices - 1,
            'close': prices,
            'volume': np.random.randint(1000, 10000, n_bars),
        }
        return pd.DataFrame(data)

# ===== å…¨å±€ç®¡ç†å™¨ =====
model_manager = ModelManager()
signal_generator = SignalGenerator()
data_fetcher = DataFetcher()

# ===== Flask Server =====
app = Flask(__name__)

@app.route('/health')
def health():
    return {'status': 'ok'}, 200

def run_flask():
    app.run(host='0.0.0.0', port=5000, debug=False, use_reloader=False)

# ===== Discord Bot äº‹ä»¶ =====
@bot.event
async def on_ready():
    logger.info(f"âœ… Bot connected as {bot.user}")
    
    # å•Ÿå‹• Flask
    threading.Thread(target=run_flask, daemon=True).start()

    # è¼‰å…¥æ¨¡å‹
    if not model_manager.models:
        model_manager.download_all_models()
        for pair in CONFIG['trading_pairs']:
            for timeframe in CONFIG['timeframes']:
                
                # ğŸŸ¢ é‚è¼¯æª¢æŸ¥ï¼šé¿å…è¼‰å…¥éŒ¯èª¤çš„æ¨¡å‹
                is_crypto = '/' in pair
                if is_crypto and timeframe == '1d':
                    continue
                if not is_crypto and timeframe == '4h':
                    continue

                model, scaler = model_manager.load_model(pair, timeframe)
                if model:
                    model_manager.models[f"{pair}_{timeframe}"] = model
                    model_manager.scalers[f"{pair}_{timeframe}"] = scaler
        
        logger.info(f"âœ… Loaded {len(model_manager.models)} models")

    # å•Ÿå‹•å¾ªç’°
    if not trading_loop.is_running():
        trading_loop.start()

# ===== äº¤æ˜“å¾ªç’° =====
@tasks.loop(minutes=15)
async def trading_loop():
    channel = bot.get_channel(DISCORD_CHANNEL_ID)
    if not channel:
        return

    logger.info("ğŸ”„ Checking signals...")
    
    for pair in CONFIG['trading_pairs']:
        for timeframe in CONFIG['timeframes']:
            
            # ğŸŸ¢ é‚è¼¯æª¢æŸ¥ï¼šå€åˆ†ç¾è‚¡èˆ‡åŠ å¯†
            is_crypto = '/' in pair
            if is_crypto and timeframe == '1d':
                continue
            if not is_crypto and timeframe == '4h':
                continue

            model_key = f"{pair}_{timeframe}"
            model = model_manager.models.get(model_key)
            scaler = model_manager.scalers.get(model_key)
            
            if not model:
                continue
                
            df = data_fetcher.get_sample_data(pair, timeframe)
            signal = signal_generator.generate_signal(pair, timeframe, model, scaler, df)
            
            if signal["action"] != "HOLD":
                await send_signal(channel, signal)

async def send_signal(channel, signal):
    color = discord.Color.green() if signal['action'] == 'BUY' else discord.Color.red()
    embed = discord.Embed(
        title=f"ğŸš€ {signal['action']} - {signal['pair']}",
        description=f"Timeframe: {signal['timeframe']}",
        color=color,
        timestamp=datetime.now()
    )
    embed.add_field(name="Confidence", value=f"{signal['confidence']:.1%}")
    embed.add_field(name="Price", value=f"${signal['current_price']:.2f}")
    await channel.send(embed=embed)

# ===== æŒ‡ä»¤å€ =====
@bot.command(name="commands")
async def cmd_commands(ctx):
    """é¡¯ç¤ºæŒ‡ä»¤åˆ—è¡¨"""
    msg = """
    **Bot Commands**
    `!status` - æŸ¥çœ‹ç‹€æ…‹
    `!signal <pair> <tf>` - æŸ¥è©¢ä¿¡è™Ÿ
    `!reload` - é‡è¼‰æ¨¡å‹
    `!config` - æŸ¥çœ‹é…ç½®
    """
    await ctx.send(msg)

@bot.command(name="status")
async def cmd_status(ctx):
    await ctx.send(f"âœ… Bot is running. Loaded {len(model_manager.models)} models.")

@bot.command(name="reload")
async def cmd_reload(ctx):
    await ctx.send("ğŸ”„ Reloading models...")
    model_manager.models.clear()
    model_manager.scalers.clear()
    model_manager.download_all_models()
    # Re-load
    for pair in CONFIG['trading_pairs']:
        for timeframe in CONFIG['timeframes']:
            
            is_crypto = '/' in pair
            if is_crypto and timeframe == '1d':
                continue
            if not is_crypto and timeframe == '4h':
                continue

            model, scaler = model_manager.load_model(pair, timeframe)
            if model:
                model_manager.models[f"{pair}_{timeframe}"] = model
                model_manager.scalers[f"{pair}_{timeframe}"] = scaler
    await ctx.send(f"âœ… Reloaded. Total models: {len(model_manager.models)}")

@bot.command(name="signal")
async def cmd_signal(ctx, pair=None, timeframe=None):
    if not pair or not timeframe:
        await ctx.send("Usage: !signal <pair> <timeframe>")
        return
    
    model_key = f"{pair}_{timeframe}"
    model = model_manager.models.get(model_key)
    scaler = model_manager.scalers.get(model_key)
    
    if not model:
        await ctx.send(f"âŒ No model for {pair} {timeframe}")
        return

    df = data_fetcher.get_sample_data(pair, timeframe)
    signal = signal_generator.generate_signal(pair, timeframe, model, scaler, df)
    await send_signal(ctx.channel, signal)

# ===== å•Ÿå‹• =====
if __name__ == "__main__":
    bot.run(DISCORD_TOKEN)
