import os
import glob
import pickle
import shutil
import pandas as pd
import numpy as np
from huggingface_hub import snapshot_download, HfApi
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE
from strategy import TradingStrategy  # ç¢ºä¿ strategy.py åœ¨åŒä¸€ç›®éŒ„æˆ– Python è·¯å¾‘ä¸­

# ===== è¨­å®š =====
HF_DATA_REPO = "zongowo111/crypto-data"   # è³‡æ–™ä¾†æº (Dataset)
HF_MODEL_REPO = "zongowo111/crypto-trading-bot" # æ¨¡å‹å»è™• (Model)
HF_TOKEN = os.getenv("HF_TOKEN")

TEMP_DATA_DIR = "./temp_dataset"
MODEL_DIR = "./models"

def train_and_upload():
    print("ğŸš€ [Step 1] ä¸‹è¼‰æ•¸æ“šé›†...")
    if os.path.exists(TEMP_DATA_DIR):
        shutil.rmtree(TEMP_DATA_DIR)
    
    try:
        # å¾ HF Dataset ä¸‹è¼‰æ‰€æœ‰ CSV
        snapshot_download(
            repo_id=HF_DATA_REPO,
            repo_type="dataset",
            local_dir=TEMP_DATA_DIR,
            token=HF_TOKEN
        )
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰æ•¸æ“šé›†å¤±æ•—: {e}")
        return
    
    print("ğŸš€ [Step 2] é–‹å§‹è¨“ç·´...")
    if not os.path.exists(MODEL_DIR):
        os.makedirs(MODEL_DIR)
    
    # æœå°‹æ‰€æœ‰ CSV æª”æ¡ˆ
    csv_files = glob.glob(f"{TEMP_DATA_DIR}/*.csv")
    print(f"æ‰¾åˆ° {len(csv_files)} å€‹æ•¸æ“šæ–‡ä»¶")

    if not csv_files:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ï¼Œè·³éè¨“ç·´ã€‚")
        return

    strategy = TradingStrategy()
    
    trained_count = 0
    for csv_path in csv_files:
        try:
            # è§£ææª”å: BTC_USD_15m.csv
            filename = os.path.basename(csv_path)
            pair_tf = filename.replace(".csv", "") # BTC_USD_15m
            
            print(f"è¨“ç·´ä¸­: {pair_tf}...")
            
            df = pd.read_csv(csv_path)
            
            # ç‰¹å¾µå·¥ç¨‹ (å¿…é ˆèˆ‡ Bot ä¸€è‡´!)
            df = strategy.calculate_features(df)
            if len(df) < 100:
                print(f"âš ï¸ {pair_tf} æ•¸æ“šä¸è¶³ (<100)ï¼Œè·³é")
                continue
            
            # å»ºç«‹ç›®æ¨™ (Target)
            # ç°¡å–®é‚è¼¯ï¼šæœªä¾†3æ ¹Kç·šæ¼²å¹… > 1.5%
            threshold = 0.015
            future_returns = df['close'].shift(-3) / df['close'] - 1
            conditions = [
                (future_returns > threshold),
                (future_returns < -threshold)
            ]
            df['target'] = np.select(conditions, [1, -1], default=0)
            
            # æ¸…ç† NaN
            df.dropna(inplace=True)
            
            # æº–å‚™è¨“ç·´æ•¸æ“š
            feature_cols = strategy.get_feature_columns()
            
            # æª¢æŸ¥ç‰¹å¾µæ˜¯å¦å­˜åœ¨
            if not all(col in df.columns for col in feature_cols):
                print(f"âš ï¸ {pair_tf} ç‰¹å¾µç¼ºå¤±ï¼Œè·³é")
                continue

            X = df[feature_cols]
            y = df['target']
            
            if len(np.unique(y)) < 2:
                print(f"âš ï¸ {pair_tf} åªæœ‰å–®ä¸€é¡åˆ¥ï¼Œè·³é")
                continue
            
            # è¨“ç·´
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
            
            scaler = StandardScaler()
            X_train_scaled = scaler.fit_transform(X_train)
            
            try:
                smote = SMOTE()
                X_res, y_res = smote.fit_resample(X_train_scaled, y_train)
            except:
                X_res, y_res = X_train_scaled, y_train
                
            model = RandomForestClassifier(n_estimators=100, max_depth=10, n_jobs=-1)
            model.fit(X_res, y_res)
            
            # ä¿å­˜
            with open(f"{MODEL_DIR}/model_{pair_tf}.pkl", 'wb') as f:
                pickle.dump(model, f)
            with open(f"{MODEL_DIR}/scaler_{pair_tf}.pkl", 'wb') as f:
                pickle.dump(scaler, f)
            
            trained_count += 1
            
        except Exception as e:
            print(f"âŒ è¨“ç·´å¤±æ•— {csv_path}: {e}")

    if trained_count > 0:
        print(f"ğŸš€ [Step 3] ä¸Šå‚³ {trained_count} å€‹æ–°æ¨¡å‹åˆ° Hugging Face...")
        try:
            api = HfApi(token=HF_TOKEN)
            api.upload_folder(
                folder_path=MODEL_DIR,
                repo_id=HF_MODEL_REPO,
                repo_type="model",
                path_in_repo=".",
                commit_message="Auto-retrained models from GitHub Actions"
            )
            print("ğŸ‰ è¨“ç·´èˆ‡æ›´æ–°å®Œæˆï¼")
        except Exception as e:
            print(f"âŒ ä¸Šå‚³å¤±æ•—: {e}")
    else:
        print("âš ï¸ æ²’æœ‰æ¨¡å‹è¢«æˆåŠŸè¨“ç·´ï¼Œè·³éä¸Šå‚³ã€‚")

if __name__ == "__main__":
    if not HF_TOKEN:
        print("âŒ éŒ¯èª¤: æœªè¨­å®š HF_TOKEN ç’°å¢ƒè®Šæ•¸")
    else:
        train_and_upload()